{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imporitng required libraries, requests for requesting/getting for the html content.\n",
    "#BeautifulSoup for scraping the content for the html pages we fecthed using tag names.\n",
    "#Pandas for playing with the data we have scraped.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "### To get the IPL Team Players and their respective cric info stats (Domestic and International)\n",
    "### We will fetch the IPL stats later\n",
    "Player_Name = []\n",
    "Player_URL = []\n",
    "Player_Ipl_Team = []\n",
    "Player_Country = []\n",
    "Team = ['Rajkot','Delhi','Mohali','Kolkata','Mumbai','Rising-Pune','Banglore','Sunrisers']\n",
    "Team_id = ['969895','969875','969899','969883','969889','969891','969877','969897']\n",
    "for i in range(0,len(Team)):\n",
    "    url = \"http://www.espncricinfo.com/indian-premier-league-2016/content/squad/\"+Team_id[i]+\".html\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content)\n",
    "    for link in soup.find_all(\"div\",{\"class\":\"large-13 medium-13 small-13 columns\"}):\n",
    "        \n",
    "        for link1 in link.find_all(\"a\"):    \n",
    "            Player_Name.append(str(link1.text).strip())\n",
    "            Player_Ipl_Team.append(Team[i])\n",
    "            Player_URL.append(str(\"http://www.espncricinfo.com\"+link1.get(\"href\")))\n",
    "            \n",
    "            ##To find players Nation and stats\n",
    "            player_response = requests.get(\"http://www.espncricinfo.com\"+link1.get(\"href\"))\n",
    "            player_soup =  BeautifulSoup(player_response.content)\n",
    "            \n",
    "            #To fetch the Nation\n",
    "            for Player_link in player_soup.find_all(\"h3\"):\n",
    "                Player_Country.append(Player_link.text)\n",
    "player_data = pandas.DataFrame({'Name':Player_Name,'URL':Player_URL,'Ipl_Team':Player_Ipl_Team,'Country':Player_Country})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(r'E:\\GITHUB\\IPL')\n",
    "\n",
    "player_data.to_csv(\"ipl_player_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
